{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5ca3109",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "# HSTaXe Cookbook: Basic Extraction for WFC3/IR \n",
    "\n",
    "This notebook contains a step-by-step guide for performing a basic spectral extraction with HSTaXe for G102 or G141 data from WFC3/IR. \n",
    "\n",
    "***\n",
    "## Learning Goals\n",
    "In this tutorial, you will:\n",
    "\n",
    "- Organize input data\n",
    "- Set up HSTaXe and prepare data for extraction\n",
    "- Learn how to handle different types of background subtraction\n",
    "- Extract 1-D spectra with a simple box extraction\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "[Introduction](#intro)<br>\n",
    "[1. Imports](#import)<br>\n",
    "[2. Setup](#setup)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[2.1 Verify Matching WCS Information](#wcs)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[2.2 Drizzling Input Data](#drizzle)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[2.3 Creating a Catalog with SExtractor](#catalog)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[2.4 Copy Catalog and Rename Mag Column](#copycat)<br>\n",
    "[3. Running HSTaXe](#axe)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[3.1. Outputs](#out) <br>\n",
    "[4. Conclusions](#conclusions)<br>\n",
    "[About this Notebook](#about)<br>\n",
    "[Citations](#cite)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2407f8e9",
   "metadata": {},
   "source": [
    "# Introduction <a id=\"intro\"></a>\n",
    "\n",
    "[HSTaXe](https://hstaxe.readthedocs.io/en/latest/index.html) is a Python package that provides spectral extraction processes for HST data. **Please be aware that running this notebook requires creating a conda environment from the provided `.yml` file in this notebook's [github repository](https://github.com/spacetelescope/hstaxe/tree/main/cookbooks).** For more details about creating the necessary environment see the notebook's README file.\n",
    "\n",
    "Below, we show the workflow for a basic specral extraction using WFC3/IR G102 grism data. **The example data we use in this notebook are available [here](https://stsci.box.com/s/j2ygj4gaqgzmp0b4xcc1h2rszz6cv9wm).** If you would like to use this notebook with the example data, please download the `example_data` subdirectory from the link above, and store it within the same parent directory as this notebook. Once you have the example data directory, this notebook is intended to run continuously without needing to edit any of the cells. \n",
    "\n",
    "In addition to the grism and direct image data, **this notebook also requires configuration files for HSTaXe, which can be downloaded [here](https://stsci.app.box.com/folder/191816748622).** The `WFC3_IR_conf` directory should be stored in the  same parent directory as this notebook, and later we will be copy them to the `CONF` subdirectory created by HSTaXe.\n",
    "\n",
    "**If you plan to use your own data with this notebook, please be aware you will be required to create an input source catalog with SExtractor.** Information regarding SExtractor including installation instructions are available [here](https://sextractor.readthedocs.io/en/latest/Installing.html). In addition to installing SExtractor, you must run the software with aXe specific configuration files. **These aXe-SExtractor configuration files can be downloaded [here](https://stsci.box.com/s/3npry36gu7ocfnuxgzwr5syj4i8r7hy8).** Once SExtractor is installed, create a `sextractor` directory in the same parent directory as this notebook, and place configuration files inside. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a91e02da",
   "metadata": {},
   "source": [
    "# 1. Imports <a id=\"import\"></a>\n",
    "\n",
    "For this workflow, we will import the following modules:\n",
    "\n",
    "- *os*, *glob* and *shutil*, for file handling\n",
    "- *numpy* for array handling\n",
    "- *astropy.io.fits* for FITS file handling\n",
    "- *astropy.table.Table* for table functions\n",
    "- *ginga.util.zscale* for image display scaling\n",
    "- *matplotlib.pyplot* for plotting\n",
    "- *stwcs.updatewcs* for matching grism and direct image WCS\n",
    "- *astrodrizzle* for creating input image mosaics\n",
    "- *hstaxe.axetasks* for performing the spectral extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3e99ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import numpy as np\n",
    "from astropy.io import fits, ascii\n",
    "from astropy.table import Table\n",
    "import matplotlib.pyplot as plt\n",
    "from ginga.util import zscale\n",
    "from stwcs import updatewcs\n",
    "from drizzlepac import astrodrizzle\n",
    "from hstaxe import axetasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3915d574",
   "metadata": {},
   "source": [
    "## 2. Setup <a id=\"setup\"></a>\n",
    "\n",
    "We'll start our basic extraction workflow by organizing our input data. A set of example data are available [here](https://stsci.box.com/s/tpbhvrqtbtwod7tr7uijexttoocy4duj) for tutorial purposes.\n",
    "\n",
    "First, we save the working directory for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159c7dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "print(f'The current directory is: {cwd}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672b237e",
   "metadata": {},
   "source": [
    "Next, we'll create directories for our grism and direct images. **HSTaXe will modify our input images in-place, so it is crucial to retain clean versions of them in another location, which will be copied into these directories.** If running this notebook multiple times, run all the lines in the next cell to clear any existing inputs; otherwise, you can run only the uncommented lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b991be",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(cwd)\n",
    "if os.path.isdir('grism_ims'):\n",
    "    shutil.rmtree('grism_ims')\n",
    "if os.path.isdir('direct_ims'):\n",
    "    shutil.rmtree('direct_ims')\n",
    "os.mkdir('grism_ims')\n",
    "os.mkdir('direct_ims')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9629fddd",
   "metadata": {},
   "source": [
    "Now, copy your images to the input directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47783cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src = '/path/to/your/grism/images/*.fits'\n",
    "src = 'example_data/grism/*.fits'\n",
    "dst = 'grism_ims/'\n",
    "for f in glob.glob(src):\n",
    "    shutil.copy(f, dst)\n",
    "\n",
    "# src = '/path/to/your/direct/images/*.fits'\n",
    "src = 'example_data/direct/*.fits'\n",
    "dst = 'direct_ims/'\n",
    "for f in glob.glob(src):\n",
    "    shutil.copy(f, dst)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d939305b",
   "metadata": {},
   "source": [
    "## 3.1 Verify WCS Information<a id=\"wcs\"></a>\n",
    "\n",
    "It is possible that the WCS in the direct and grism images differ. In this section we will use a function to process all the direct and grism images to verify that the WCS information is consistent throughout. If there is any disagreement in WCS information we call updatewcs with the database keyword set to False, which will roll back all the solutions to the original distortion-corrected WCS. For more information regarding HST WCS and improved absolute astrometry please see WFC3 Instrument Science Report 2022-06 (Mack et. al 2022). For documentations on updatewcs please see here.\n",
    "\n",
    "Before running updatewcs, we need to set CRDS environment variables. We will point to a subdirectory called crds_cache/ using the IREF environment variable. The IREF variable is used for WFC3 reference files and different instruments use other variables, e.g. JREF for ACS. You have the option to permanently add these environment variables to your user profile by adding the path in your shell's configuration file. If you're using bash, you would edit the ~/.bash_profile file with lines such as:\n",
    "\n",
    "    export CRDS_PATH=\"$HOME/crds_cache\"\n",
    "    export CRDS_SERVER_URL=\"https://hst-crds.stsci.edu\"\n",
    "    export iref=\"${CRDS_PATH}/references/hst/iref/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f0ef80",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CRDS_SERVER_URL'] = 'https://hst-crds.stsci.edu'\n",
    "os.environ['CRDS_SERVER'] = 'https://hst-crds.stsci.edu'\n",
    "if 'CRDS_PATH' not in os.environ.keys():\n",
    "    os.environ['CRDS_PATH'] = os.path.join(os.environ['HOME'],'crds_cache')\n",
    "if 'iref' not in os.environ.keys():\n",
    "    os.environ['iref'] = '$HOME/crds_cache/references/hst/iref/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2baebde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_wcs(images):\n",
    "    \"\"\" A helper function to verify the active world coordinate solutions match and roll them back if they do not \n",
    "    \n",
    "    Parameter\n",
    "    ---------\n",
    "    images : list \n",
    "        a list of grism and direct images \n",
    "        \n",
    "    Return\n",
    "    ------\n",
    "    N/A\n",
    "    \"\"\"\n",
    "    \n",
    "    direct_wcs = []\n",
    "    grism_wcs = []\n",
    "\n",
    "    for f in images:\n",
    "        # get filter for image to distinguish between direct and grism\n",
    "        filt = fits.getval(f, 'FILTER')\n",
    "        \n",
    "        hdul = fits.open(f)\n",
    "        db_bool = 'WCSCORR' not in hdul\n",
    "        hdul.close()\n",
    "        \n",
    "        try:\n",
    "            # get the active solution from the file's \"SCI\" extension\n",
    "            wcsname = fits.getval(f, 'WCSNAME', ext=('SCI', 1))\n",
    "            if db_bool == True:\n",
    "                updatewcs.updatewcs(f,use_db=db_bool)\n",
    "        except KeyError:\n",
    "            updatewcs.updatewcs(f,use_db=db_bool)\n",
    "            wcsname = fits.getval(f, 'WCSNAME', ext=('SCI', 1))\n",
    "        \n",
    "        # seperate between direct and grism\n",
    "        if 'G' in filt:\n",
    "            grism_wcs.append(wcsname)\n",
    "        if 'F' in filt:\n",
    "            direct_wcs.append(wcsname)\n",
    "\n",
    "    # get the number of unique active solutions in the direct and grism images       \n",
    "    num_wcs_direct = len(set(direct_wcs))\n",
    "    num_wcs_grism = len(set(grism_wcs))\n",
    "\n",
    "    # roll back WCS on all files if there is more than one active solution for either direct or grism images\n",
    "    if num_wcs_direct > 1 or num_wcs_grism > 1:\n",
    "        [updatewcs.updatewcs(file,use_db=False) for file in images]\n",
    "        print('WCS reset complete')\n",
    "\n",
    "    # roll back WCS on all files if the active solution for the direct images do not match the grism images\n",
    "    elif set(direct_wcs) != set(grism_wcs):\n",
    "        [updatewcs.updatewcs(file,use_db=False) for file in images]\n",
    "        print('WCS reset complete')\n",
    "\n",
    "    # do nothing if there is one unique active solution and they match\n",
    "    elif set(direct_wcs) == set(grism_wcs):\n",
    "        print(f\"No WCS update needed. All grism and direct images us WCS: {grism_wcs[0]}.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc96e0a7",
   "metadata": {},
   "source": [
    "Now, we'll run `crds bestrefs` to fetch the reference files requried by `updatewcs`, and then run our helper function. The example data we provide **do** have a WCS mismatch; the next cell will reset them.\n",
    "\n",
    "If you've never used `bestrefs` before, the next cell may take a few minutes to download necessary reference file mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3b839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grism_ims = glob.glob('grism_ims/*.fits')\n",
    "direct_ims = glob.glob('direct_ims/*.fits')\n",
    "all_images = grism_ims + direct_ims\n",
    "for file in all_images:\n",
    "    command_line_input = 'crds bestrefs --files {:} --types IDCTAB --sync-references=1 --update-bestrefs'.format(file)\n",
    "    os.system(command_line_input)\n",
    "check_wcs(all_images)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f079201a",
   "metadata": {},
   "source": [
    "## 2.2 Drizzling the Input Data<a id=\"drizzle\"></a>\n",
    "The next step is to drizzle the grism images. We'll need a list of the image names to feed to AstroDrizzle. After that, we'll do the same for the direct images, but use the drizzled grism image as a reference, which will ensure proper registration between the data. HSTaXe will use these linked drizzle images to locate spectral traces based on the positions of sources in the direct images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cdf196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list file using images in grism directory\n",
    "os.chdir('grism_ims')\n",
    "\n",
    "lis = open('grism.lis', 'w')\n",
    "for f in sorted(os.listdir('.')):\n",
    "    if os.path.splitext(f)[1]=='.fits':\n",
    "        lis.write(f)\n",
    "        lis.write('\\n')\n",
    "lis.close()\n",
    "\n",
    "!cat grism.lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f806c612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drizzle grism images. If only using one input image, set blot, median, driz_cr to False\n",
    "# If your input images were flc images rather than flt images, change the extension to 'drc.fits'\n",
    "astrodrizzle.AstroDrizzle('@grism.lis', output='grism', \n",
    "                          build=True, blot=True, median=True, driz_cr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679312fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List file for direct images\n",
    "os.chdir(cwd)\n",
    "os.chdir('direct_ims')\n",
    "\n",
    "lis = open('direct.lis', 'w')\n",
    "for f in sorted(os.listdir('.')):\n",
    "    if os.path.splitext(f)[1]=='.fits':\n",
    "        lis.write(f)\n",
    "        lis.write('\\n')\n",
    "lis.close()\n",
    "\n",
    "!cat direct.lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e9d4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drizzle direct images, using drizzled grism mosaic as a reference to ensure proper registration.\n",
    "# If only using a single direct image, set the CR rejection keywords to False.\n",
    "# If your input images were flc images rather than flt images, change the extension to 'drc.fits'\n",
    "ref = '../grism_ims/grism_drz.fits[1]'\n",
    "astrodrizzle.AstroDrizzle('@direct.lis', output='direct', build=True, \n",
    "                          final_wcs=True, driz_sep_wcs=True,\n",
    "                          driz_sep_refimage=ref, final_refimage=ref,\n",
    "                          blot=True, median=True, driz_cr=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9187eb",
   "metadata": {},
   "source": [
    "Your grism and direct images should now be aligned. For the WFC3/IR grisms, there should be very little vertical offset between the positions of sources in the direct image and their correspondents in the grism image. We'll perform a quick visual check here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a28fa6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir(cwd)\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10,10), dpi=200)\n",
    "\n",
    "d = fits.getdata('direct_ims/direct_drz.fits', 1)\n",
    "z1,z2 = zscale.zscale(d)\n",
    "im1 = axs[0].imshow(d, origin='lower', cmap='Greys_r', vmin=z1, vmax=z2)\n",
    "axs[0].set_title('direct_drz.fits')\n",
    "fig.colorbar(im1,shrink=0.4,pad=0.01)\n",
    "\n",
    "d = fits.getdata('grism_ims/grism_drz.fits', 1)\n",
    "z1,z2 = zscale.zscale(d)\n",
    "im2 = axs[1].imshow(d, origin='lower', cmap='Greys_r', vmin=z1, vmax=z2)\n",
    "axs[1].set_title('grism_drz.fits')\n",
    "fig.colorbar(im2,shrink=0.4,pad=0.01)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30810db8",
   "metadata": {},
   "source": [
    "## 2.3 Creating a Catalog with SExtractor <a id=\"catalog\"></a>\n",
    "\n",
    "This section is intended for anyone using data other than the `example_data` provided for this notebook. Since we also provide a catalog in the `example_data` directory and will not formally run SExtractor here, we want to explain the process behind using the drizzle image to create a new catalog with SExtractor. **Please refer to the links in the [Introduction](#intro) section for instructions regarding installing SExtractor and downloading the necessary aXe-SExtractor configuration files.**\n",
    "\n",
    "HSTaXe will look for a highly specific format in the catalog, and does not always give clear error messages when something within the catalog is awry. If creating a catalog yourself, please follow the next steps carefully:\n",
    "\n",
    "1. Copy the drizzled direct image into the `sextractor` directory (once created), which contains HSTaXe-appropriate configuration files for SExtractor.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<u>Example code:</u>\n",
    "```python\n",
    "shutil.copy('direct_ims/direct_drz.fits', 'sextractor/')\n",
    "```\n",
    "2. With SExtractor installed, run the follow\"ing command from within the `sextractor` directory that you created:\n",
    "   \n",
    "   `sex -c aXe.sex direct_drz.fits[1] -DETECT_THRESH 5 -MAG_ZEROPOINT 26.4525`\n",
    "\n",
    "    Note that the value for the `DETECT_THRESH` keyword, which sets the minimum value for pixels to be considered, may be changed appropriately for your data. `MAG_ZEROPOINT` should also be changed to match the magnitude zeropoint of the direct image filter for your data. A table is provided below containing the pivot wavelengths and zeropoints for the WFC3/IR grism reference filters.\n",
    "    \n",
    "| Filter | Pivot Wavelength (nm) | Zeropoint (ABmag |\n",
    "|:--------|-----------------------|------------------|\n",
    "| F098M  |         986.4         |      25.666      |\n",
    "| F105W  |          1055         |      26.264      |\n",
    "| F140W  |          1392         |      26.450      |\n",
    "| F160W  |          1537         |      25.936      |\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<u>Example code:</u>\n",
    "```python\n",
    "os.chdir('sextractor')\n",
    "detect_thresh = 10\n",
    "cl_input = f'sex -c aXe.sex direct_drz.fits[1] -DETECT_THRESH {detect_thresh} -MAG_ZEROPOINT 25.666'\n",
    "os.system(cl_input)\n",
    "``` \n",
    "3. At this point you should have created a catalog. The next steps include copying the file into the `direct_ims` directory and editing the name of the `MAG_ISO` column. See [Section 2.3](#copycat) for information regarding renaming the `MAG_ISO` column. \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<u>Example code:</u>\n",
    "```python\n",
    "os.chdir(cwd)\n",
    "shutil.copy('sextractor/aXe.cat', 'direct_ims')\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee9f377a",
   "metadata": {},
   "source": [
    "## 2.4 Copy Catalog and Rename Mag Column <a id=\"copycat\"></a>\n",
    "\n",
    "The catalog corresponding to the data used in this notebook is included in the `example_data` directory downloaded in the Introduction section. Start by copying the catalog into the `direct_ims` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087eb4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the example catalog to the direct image directory:\n",
    "os.chdir(cwd)\n",
    "shutil.copy('example_data/aXe.cat', 'direct_ims');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0058a1c3",
   "metadata": {},
   "source": [
    "Examine the catalog. The \"MAG_ISO\" column must be renamed to \"MAG_F####\" for the catalog to be correctly read in by HSTaXe. Where \"####\" is the pivot wavelength of the direct image filter in nm (Å for WFC3/UVIS, e.g. 4971 for F200LP and 1392 for F140W). Please see WFC3 Instrument Handbook Section 7.5 [\"IR Spectral Elements\"](https://hst-docs.stsci.edu/wfc3ihb/chapter-7-ir-imaging-with-wfc3/7-5-ir-spectral-elements) for information about UVIS filter pivot wavelengths. You can also refer to the table above as a quick-reference for the pivot wavelength of the recommended direct image filters for the IR grisms.\n",
    "\n",
    "Any lines in the catalog containing clearly spurious detections, such as those with magnitudes of 99.0, should also be removed. **Note**: Removing spurious detections must be done manually.\n",
    "\n",
    "Lastly, locate the lines containing the sources whose spectra you want to extract and note the line number from the NUMBER column. This will be used later to identify the BEAM number for your object in the output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d555574d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = Table.read('direct_ims/aXe.cat', format='ascii.sextractor')\n",
    "cols_to_show = ['NUMBER', 'X_IMAGE', 'Y_IMAGE', 'A_IMAGE', 'B_IMAGE', 'MAG_ISO', 'MAGERR_ISO']\n",
    "cat[cols_to_show].show_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ee9d2a",
   "metadata": {},
   "source": [
    "To avoid having to edit the column information manually in the SExtractor catalog, there is a helper function below called `edit_catalog_pivot`. It takes in the SExtractor catalog, output file path/name, and the pivot wavelength value and edits the information and writes to the output file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3afd91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_catalog_pivot(inputfile, outputfile, pivot_wave):\n",
    "    \"\"\" Function to edit the auto-generated sextractor header/column name so aXe will run\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        inputfile : str\n",
    "            The full path to the input catalog including filename\n",
    "        outputfile : str\n",
    "            The full path to the output catalog including filename\n",
    "        pivot_wave : int or str\n",
    "            The pivot wavelength of filter used in the driect image\n",
    "            For UVIS please use 4 digits in units of Angstrom and \n",
    "            for IR please use 4 ditits in units of nanometers \n",
    "            \n",
    "        Return\n",
    "        ------\n",
    "        Nothing. But a file is written to `outputfile`\n",
    "    \"\"\"\n",
    "    # Read in the input catalog\n",
    "    with open(inputfile, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    with open(outputfile, 'w') as f:\n",
    "        # Find the mag_iso row and replace with pivot wavelength\n",
    "        for line in lines:\n",
    "            line = line.replace('MAG_ISO', f'MAG_F{pivot_wave}')\n",
    "            f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde19974",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputfile = 'direct_ims/aXe.cat'\n",
    "outputfile = 'direct_ims/aXe_ir_f098m.cat'\n",
    "pivot_wave = 986 # nm\n",
    "edit_catalog_pivot(inputfile, outputfile, pivot_wave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38ac667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell to filter your catalog for your sources\n",
    "# In this example, we sort to identify the brightest sources\n",
    "cat = Table.read(outputfile, format='ascii.sextractor')\n",
    "cat.sort(f'MAG_F{pivot_wave}')\n",
    "cols_to_show = ['NUMBER', 'X_IMAGE', 'Y_IMAGE', 'A_IMAGE', 'B_IMAGE', 'MAG_F986', 'MAGERR_ISO']\n",
    "cat[cols_to_show].show_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b64214",
   "metadata": {},
   "source": [
    "# 3. Running HSTaXe<a id=\"aXe\"></a>\n",
    "\n",
    "With the catalog generated and edited, we can now move on to working with HSTaXe. We'll set up a few additional directories and environment variables that point to them, while clearing out any previous data or outputs in these directories. We'll also copy our data into the fresh `DATA` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef990243",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(cwd)\n",
    "\n",
    "for dirr in ['DATA','CONF','OUTPUT']:\n",
    "    if os.path.isdir(dirr):\n",
    "        shutil.rmtree(dirr)\n",
    "    os.mkdir(dirr)\n",
    "    \n",
    "os.environ['AXE_IMAGE_PATH'] = './DATA/' \n",
    "os.environ['AXE_CONFIG_PATH'] = './CONF/'\n",
    "os.environ['AXE_OUTPUT_PATH'] = './OUTPUT/'\n",
    "\n",
    "dsrc = 'direct_ims/*flt.fits'\n",
    "gsrc = 'grism_ims/*flt.fits'\n",
    "csrc = 'WFC3_IR_conf/*'\n",
    "\n",
    "for files in [dsrc, gsrc, csrc]:\n",
    "    if '_ims' in files:\n",
    "        dirr = 'DATA'\n",
    "    elif 'conf' in files:\n",
    "        dirr = 'CONF'\n",
    "    for f in glob.glob(files):\n",
    "        shutil.copy(f, dirr)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0eb2d7",
   "metadata": {},
   "source": [
    "Next, we define the field-of-view boundaries for the detector. We'll pass this information to the `iolprep` task, which will let it include in the input object lists (IOLs) it generates, objects whose direct image locations fall outside of the chip but whose spectral traces do fall onto the chip.\n",
    "\n",
    "For WFC3/IR, the [left, right, top, bottom] extensions, in pixels, are [183, 85, 50, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55227aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOV = '183,85,50,50'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8662a6e1",
   "metadata": {},
   "source": [
    "Now we'll run `iolprep` to generate our IOLs, which are object catalogs for each individual direct image, from the drizzled direct image and its catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9068904",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(cwd)\n",
    "os.chdir('direct_ims')\n",
    "\n",
    "axetasks.iolprep(drizzle_image = 'direct_drz.fits',\n",
    "                input_cat = 'aXe_ir_f098m.cat',\n",
    "                dimension_in = FOV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c82e3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the IOLs to the aXe DATA directory\n",
    "os.chdir(cwd)\n",
    "for f in glob.glob('direct_ims/*_?.cat'):\n",
    "    shutil.copy(f, 'DATA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e616117",
   "metadata": {},
   "source": [
    "The last step before extracting our spectra is to generate a file which contains on each line the names of a grism image, IOL name, and associated direct image. This is best done manually, to ensure that each grism image lines up with the appropriate direct image. For the example data, a file called `example.lis` is provided.\n",
    "\n",
    "With this list, we run `axeprep`, which prepares the individual images for spectral extraction. This step is also responsible for perfoming a global background subtraction, if desired. This is controlled by the `backgr` keyword. \n",
    "\n",
    "Note that the `configs` and `backims` keywords should be matched to the data you have. E.g., if you are working with G102 data with direct images in F098M, the config file should be `G102.F098M.V4.32.conf`. If you are not performing a global background subtraction, `backims` is not required, but should be matched to the correct grism if you are. **Note: we do not currently recommend using HSTaXe to perform global background subtraction. A more reliable method will be added to this notebook in the near future.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d9d6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the example list file\n",
    "os.chdir(cwd)\n",
    "shutil.copy('example_data/example.lis', '.')\n",
    "os.rename('example.lis', 'aXe.lis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a044ea24",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(cwd)\n",
    "\n",
    "axetasks.axeprep(inlist='aXe.lis',\n",
    "                     configs='G102.F098M.V4.32.conf',\n",
    "                     backgr=False,\n",
    "                     norm=False,\n",
    "                     mfwhm=3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa06bc7f",
   "metadata": {},
   "source": [
    "The last HSTaXe task to run is `axecore`, which performs the actual extraction and generates output files. Again, the configuration file and sky background arguments should be matched to the spectral elements used for your data.\n",
    "\n",
    "Local background subtraction is also performed by this step, if desired. The following keywords are critical for local background:\n",
    "\n",
    "* `back`: This argument is the flag to trigger local background subtraction.\n",
    "* `np`: Defines the number of pixels on either side of the spectral trace (beam) used to calculate the local background from.\n",
    "* `interp`: Sets the interpolation method for the local background (-1=median, 0=mean, ≥1=nth order polynomial)\n",
    "* `backfwhm`: The FWHM specifying the width of the background pixel extraction table\n",
    "\n",
    "More information on background handling, both global and local, with `HSTaXe` can be found in the documentation [here](https://hstaxe.readthedocs.io/en/latest/hstaxe/description.html#sky-background)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d147d692",
   "metadata": {},
   "outputs": [],
   "source": [
    "axetasks.axecore('aXe.lis',\n",
    "                 'G102.F098M.V4.32.conf',\n",
    "                 fconfterm=None,\n",
    "                 extrfwhm=4.,\n",
    "                 drzfwhm=3.,\n",
    "                 orient=False,\n",
    "                 back=False,\n",
    "                 weights=True,\n",
    "                 slitless_geom=True,\n",
    "                 cont_model='gauss',\n",
    "                 sampling='drizzle',\n",
    "                 exclude=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef080fa",
   "metadata": {},
   "source": [
    "## 3.1. Outputs<a id=\"out\"></a>\n",
    "\n",
    "Each grism input file will have several corresponding output files. For now, let's take a look at the STP files, which contain 2D \"stamps\" of the extracted spectral traces; and the SPC files, which contain our 1D extracted spectra.\n",
    "\n",
    "We'll need the line numbers from the original source catalog we generated to identify the BEAM number for the object whose spectrum we want. For the example data, The target is the bright planetary nebula in the middle-left of the drizzled direct image. Its number in the example catalog is 19.\n",
    "\n",
    "First, let's examine the stamps from the STP files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5d4e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam = '19'\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10,6))\n",
    "\n",
    "for i, f in enumerate(glob.glob('OUTPUT/*STP.fits')):\n",
    "    with fits.open(f) as hdul:\n",
    "        d = hdul[f'BEAM_{beam}A'].data\n",
    "        z1,z2 = zscale.zscale(d)\n",
    "        im = axes[i].imshow(d, origin='lower', cmap='Greys_r', vmin=z1, vmax=z2)\n",
    "        axes[i].set_title(os.path.basename(f))\n",
    "        \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fa703c",
   "metadata": {},
   "source": [
    "And now, we can finally look at our extracted spectra from the SPC files. For the example data, we've plotted the expected location of several emission lines that should be present in the planetary nebula spectrum (from Table 2 in [Bohlin et al. 2015](https://www.stsci.edu/files/live/sites/www/files/home/hst/instrumentation/wfc3/documentation/instrument-science-reports-isrs/_documents/2015/WFC3-2015-10.pdf))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f2a7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10,6), dpi=150)\n",
    "\n",
    "for i, f in enumerate(glob.glob('OUTPUT/*2.SPC.fits')):\n",
    "    with fits.open(f) as hdul:\n",
    "        d = hdul[f'BEAM_{beam}A'].data\n",
    "        wl = d['LAMBDA']\n",
    "        flux = d['FLUX']\n",
    "        error = d['FERROR']\n",
    "        contam = d['CONTAM']\n",
    "        xrange = (wl>8000) & (wl<11500)\n",
    "        \n",
    "        ax.errorbar(wl[xrange],flux[xrange],error[xrange], label=f'{os.path.basename(f)}')\n",
    "        \n",
    "# ax.set_title(os.path.basename(f))\n",
    "ax.axvline(9070.0, ls=':', c='k') # SIII\n",
    "ax.axvline(9535.1, ls=':', c='k') # SIII+P epsilon\n",
    "ax.axvline(10060.2, ls=':', c='k') # HI P7\n",
    "ax.axvline(10833.5, ls=':', c='k') # HeI\n",
    "\n",
    "\n",
    "ax.set_ylabel(r'Flux ($erg/cm^2/s/\\AA$)')\n",
    "ax.set_xlabel(r'Wavelength ($\\AA$)')\n",
    "ax.legend(loc='upper left')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b1338f",
   "metadata": {},
   "source": [
    "# 4. Conclusions <a id=\"conclusions\"></a>\n",
    "\n",
    "Thank you for walking through this spectral extraction workflow. You should now be able to perform a basic extraction on WFC3/IR data using HSTaXe.\n",
    "\n",
    "For additional information on the WFC3 grisms, please visit the [grism resources](https://www.stsci.edu/hst/instrumentation/wfc3/documentation/grism-resources) and [grism data analysis](https://www.stsci.edu/hst/instrumentation/wfc3/documentation/grism-resources/grism-data-analysis) webpages.\n",
    "\n",
    "Further workflow cookbooks are available on the [HSTaXe GitHub](https://github.com/spacetelescope/HSTaXe), including a more advanced IR extraction, and a UVIS extraction. For detailed information on HSTaXe, please visit the [documentation webpage](https://hstaxe.readthedocs.io/en/latest/index.html). Lastly, if you have questions regarding this notebook or using WFC3 data with HSTaXe please contact our WFC3 [Help Desk](https://stsci.service-now.com/hst).\n",
    "\n",
    "\n",
    "**Congratulations, you have completed the notebook.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a339b9d",
   "metadata": {},
   "source": [
    "## About this Notebook <a id=\"about\"></a>\n",
    "\n",
    "**Author:** Aidan Pidgeon and Benjamin Kuhn, WFC3 Instrument Team\n",
    "\n",
    "**Special Thanks to:** \n",
    " - Dr. Nor Pirzkal, for creating the original workflow that was adapted into this notebook\n",
    " - Ricky O'Steen and Duy Nguyen, for their fantastic work in updating the HSTaXe module\n",
    " - Debopam Som, for support in testing the HSTaXe workflow\n",
    "\n",
    "**Updated On:** 2022-01-13\n",
    "\n",
    "## Citations <a id=\"cite\"></a>\n",
    "\n",
    "If you use `astropy`, `drizzlepac`, `matplotlib` or `numpy` for published research, please cite the\n",
    "authors. Follow this link for more information about citing the libraries:\n",
    "\n",
    "* [Citing `astropy`](https://www.astropy.org/acknowledging.html)\n",
    "* [Citing `drizzlepac`](https://drizzlepac.readthedocs.io/en/latest/LICENSE.html)\n",
    "* [Citing `matplotlib`](https://matplotlib.org/stable/users/project/citing.html)\n",
    "* [Citing `numpy`](https://numpy.org/citing-numpy/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "61185e4153bd22ba192429d01ef156e5c02e7fcbb7ff0f03ca08685bc8232e35"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
